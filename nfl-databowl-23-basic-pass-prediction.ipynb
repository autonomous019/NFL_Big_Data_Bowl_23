{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **NFL Databowl 23 Basic Pass Prediction**\n\nusing boosted trees to determine if a pass will be complete or incomplete given a offensive personnel package and a defensive personnel package plus coverage formation and coverage type.\n\nResults: In feature importance below, shows that the most important feature given the dataset is the Dropback Type, pass coverage, and then play action. ","metadata":{"id":"KRMqaM8xCbx5"}},{"cell_type":"code","source":"#Imported Stuff\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport seaborn as sns\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom hyperopt import hp\nfrom hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\nfrom sklearn.model_selection import cross_val_score\nimport pickle\n\n'''\nML work flow:\n1. Collect the data\n2. Visualize the data\n3. Clean the data\n4. Train the model\n5. Evaluate\n6. Hyperparameter tuning\n7. Choose the best model and prediction\nsee for more info, https://towardsdatascience.com/regression-analysis-for-beginners-using-tree-based-methods-2b65bd193a7#bb44\n\n\n'''\n\nplt.interactive(True) #interactive mode to display plots\n#plt.savefig('myplot1.png') plot to a file instead","metadata":{"id":"7bX3wRlP-N-M","execution":{"iopub.status.busy":"2022-11-05T02:22:10.039596Z","iopub.execute_input":"2022-11-05T02:22:10.040326Z","iopub.status.idle":"2022-11-05T02:22:12.461798Z","shell.execute_reply.started":"2022-11-05T02:22:10.040224Z","shell.execute_reply":"2022-11-05T02:22:12.459619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Google Drive Access\nimport os\n\n'''\nfrom google.colab import drive\ndrive.mount('/content/gdrive')\nos.chdir(\"//content/gdrive/MyDrive/nfl-big-data-bowl-2023/\")\n\ndata_dir = \"/content/gdrive/My Drive/nfl-big-data-bowl-2023/\"\nsave_dir = \"/content/gdrive/My Drive/nfl-big-data-bowl-2023/models/\"\n'''\n#if on kaggle\ndata_dir = \"../input/play-predictor-data/play_predictor_data.csv\"\nOUTPUT_DIR = './'","metadata":{"id":"1l_4846fDOFo","outputId":"031ff973-579d-41b3-b25c-ad3aa695d690","execution":{"iopub.status.busy":"2022-11-05T02:22:12.464883Z","iopub.execute_input":"2022-11-05T02:22:12.465699Z","iopub.status.idle":"2022-11-05T02:22:12.477680Z","shell.execute_reply.started":"2022-11-05T02:22:12.465517Z","shell.execute_reply":"2022-11-05T02:22:12.473815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nwith c,i,in: 7566\nplayAction = 1 and passResult = C returns 1116 of 4620 24.1% of C pass plays AVG gain 13.54yds per pass Action play\nplayAction = 0 and passResult = C returns 3504 of 4620 75.9%  AVG gain 11.08yds per pass play W/O play Action\nplayAction = 1 and passResult = I returns 621 of 2756 22.5% of I pass plays\nplayAction = 0 and passResult = I returns 2135 of 2756 77.4%\nplayAction = 1 and passResult = IN returns 41 of 4620  //slightly less interceptions on plays with playAction 2 21.5% of INs\nplayAction  = 0 and passResult = IN returns 149 of 4620 // 78.4% of interceptions\n\nslightly less interceptions and incompletions with playAction  = 1\n#analysis would need to be done on a team by team basis\n\ngeneral observation: OL should study Wing Chun techniques\n\ncombine data: https://nflcombineresults.com/nflcombinedata.php?year=2022&pos=OT&college=\n\nunderstanding passing table in db: https://fantasydata.com/fantasy-football-advanced-metrics-explained\n\ndefensive fronts: https://www.playerprofiler.com/article/meet-the-metric-base-stacked-and-light-fronts/\n\nGeneral Football Analytic Coding: https://www.opensourcefootball.com/posts/2020-08-24-getting-into-sports-analytics/\n\n\n'''","metadata":{"id":"5VEoqrP_Kgr7","outputId":"6fdb50b6-8ad7-4ec0-a7b8-ac372ff724b0","execution":{"iopub.status.busy":"2022-11-05T02:22:12.479898Z","iopub.execute_input":"2022-11-05T02:22:12.480700Z","iopub.status.idle":"2022-11-05T02:22:12.505231Z","shell.execute_reply.started":"2022-11-05T02:22:12.480647Z","shell.execute_reply":"2022-11-05T02:22:12.502816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Exploratory Data Analysis (EDA)**","metadata":{"id":"5wPngyIHC5bI"}},{"cell_type":"code","source":"\n#Reading Dataset\ndf = pd.read_csv(data_dir)\nprint(df.head())\n\n\nprint(df.shape)","metadata":{"id":"6JtXcioK-cvo","outputId":"610d835e-dec2-4a39-dbda-711706dfc725","execution":{"iopub.status.busy":"2022-11-05T02:22:12.509308Z","iopub.execute_input":"2022-11-05T02:22:12.509926Z","iopub.status.idle":"2022-11-05T02:22:12.604428Z","shell.execute_reply.started":"2022-11-05T02:22:12.509885Z","shell.execute_reply":"2022-11-05T02:22:12.602989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for null values\nprint(df.isnull().sum())\n\nprint(df.describe())\n\ndf = df.dropna()\nprint(len(df))","metadata":{"id":"84jfjTXx-c7B","outputId":"e8e8e939-e3c7-4932-e572-7e6d85d9c6d7","execution":{"iopub.status.busy":"2022-11-05T02:22:12.606164Z","iopub.execute_input":"2022-11-05T02:22:12.607393Z","iopub.status.idle":"2022-11-05T02:22:12.662800Z","shell.execute_reply.started":"2022-11-05T02:22:12.607338Z","shell.execute_reply":"2022-11-05T02:22:12.661375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"FaV-dNvT8oFG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#need to convert all categorial columns to integer columns\n\ndf['offenseFormation'].replace(['SHOTGUN', 'EMPTY', 'SINGLEBACK', 'I_FORM', 'JUMBO', 'PISTOL', 'WILDCAT'],\n                        [1, 2, 3, 4, 5, 6, 7], inplace=True)\n\ndf['passResult'].replace(['C', 'I', 'S', 'R', 'IN'],\n                        [0, 1, 2, 3, 4], inplace=True)\n\ndf['offenseFormation'].replace(['SHOTGUN', 'EMPTY', 'SINGLEBACK', 'I_FORM', 'JUMBO', 'PISTOL', 'WILDCAT'],\n                        [1, 2, 3, 4, 5, 6, 7], inplace=True)\n\ndf['personnelO'].replace(['1 RB, 1 TE, 3 WR', \n'1 RB, 2 TE, 2 WR', \n'0 RB, 2 TE, 3 WR',\n'1 RB, 0 TE, 4 WR', \n'2 RB, 1 TE, 2 WR',\n'2 RB, 0 TE, 3 WR', \n'2 RB, 2 TE, 1 WR', \n'1 RB, 3 TE, 1 WR',\n'2 RB, 3 TE, 0 WR',\n'0 RB, 0 TE, 5 WR',\n'0 RB, 1 TE, 4 WR',\n'6 OL, 2 RB, 2 TE, 0 WR',\n'2 QB, 2 RB, 0 TE, 2 WR',\n'2 QB, 1 RB, 1 TE, 2 WR',\n'6 OL, 1 RB, 1 TE, 2 WR',\n'2 QB, 1 RB, 2 TE, 1 WR',\n'6 OL, 1 RB, 2 TE, 1 WR',\n'2 QB, 1 RB, 0 TE, 3 WR',\n'6 OL, 2 RB, 1 TE, 1 WR',\n'3 RB, 0 TE, 2 WR',\n'2 QB, 6 OL, 1 RB, 1 TE, 1 WR',\n'0 RB, 3 TE, 2 WR',\n'6 OL, 1 RB, 3 TE, 0 WR',\n'6 OL, 2 RB, 0 TE, 2 WR',\n'6 OL, 1 RB, 0 TE, 3 WR',\n'1 RB, 1 TE, 2 WR,1 LB',\n'1 RB, 4 TE, 0 WR',\n'2 QB, 2 RB, 1 TE, 1 WR',\n'2 QB, 1 RB, 3 TE, 0 WR',\n'7 OL, 1 RB, 0 TE, 2 WR'],\n                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], inplace=True)\n\n\ndf['personnelD'].replace(['4 DL, 2 LB, 5 DB',\n'4 DL, 4 LB, 3 DB',\n'3 DL, 3 LB, 5 DB',\n'4 DL, 3 LB, 4 DB',\n'3 DL, 4 LB, 4 DB',\n'2 DL, 4 LB, 5 DB',\n'2 DL, 2 LB, 7 DB',\n'1 DL, 5 LB, 5 DB',\n'2 DL, 3 LB, 6 DB',\n'4 DL, 1 LB, 6 DB',\n'3 DL, 2 LB, 6 DB',\n'5 DL, 2 LB, 4 DB',\n'6 DL, 1 LB, 4 DB',\n'3 DL, 1 LB, 7 DB',\n'1 DL, 4 LB, 6 DB',\n'4 DL, 6 LB, 1 DB',\n'0 DL, 3 LB, 8 DB',\n'1 DL, 3 LB, 7 DB',\n'5 DL, 1 LB, 5 DB',\n'5 DL, 3 LB, 3 DB',\n'0 DL, 5 LB, 6 DB',\n'2 DL, 5 LB, 4 DB',\n'6 DL, 3 LB, 2 DB',\n'3 DL, 5 LB, 3 DB',\n'5 DL, 5 LB, 1 DB',\n'1 DL, 2 LB, 8 DB',\n'6 DL, 4 LB, 1 DB',\n'4 DL, 5 LB, 2 DB',\n'6 DL, 2 LB, 3 DB'],\n                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], inplace=True)\n\ndf['dropBackType'].replace(['TRADITIONAL',\n'SCRAMBLE_ROLLOUT_RIGHT',\n'DESIGNED_ROLLOUT_RIGHT',\n'SCRAMBLE',\n'DESIGNED_ROLLOUT_LEFT',\n'UNKNOWN',\n'DESIGNED_RUN',\n'SCRAMBLE_ROLLOUT_LEFT'],\n                        [1, 2, 3, 4, 5, 6, 7, 8], inplace=True)\n\ndf['pff_passCoverage'].replace([\n'Cover-1',\n'Cover-3',\n'Cover-6',\n'Quarters',\n'Cover-2',\n'2-Man',\n'Cover-0',\n'Prevent',\n'Bracket',\n'Red Zone',\n'Miscellaneous',\n'Goal Line'],\n                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], inplace=True)\n\n\n\ndf['pff_passCoverageType'].replace(['Man', 'Zone', 'Other'],\n                        [1, 2, 3], inplace=True)\n\ndf['playDirection'].replace(['left', 'right'],\n                        [1, 2], inplace=True)\n\n\n","metadata":{"id":"kutCp5g4ThT0","execution":{"iopub.status.busy":"2022-11-05T02:22:12.665836Z","iopub.execute_input":"2022-11-05T02:22:12.666857Z","iopub.status.idle":"2022-11-05T02:22:12.753045Z","shell.execute_reply.started":"2022-11-05T02:22:12.666802Z","shell.execute_reply":"2022-11-05T02:22:12.752006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.iloc[: , 1:]\n\ndf.head()","metadata":{"id":"uF6QMgB6DT-e","outputId":"1d11557d-0197-4488-f00e-b9c03f6ed4bc","execution":{"iopub.status.busy":"2022-11-05T02:22:12.755778Z","iopub.execute_input":"2022-11-05T02:22:12.756403Z","iopub.status.idle":"2022-11-05T02:22:12.776470Z","shell.execute_reply.started":"2022-11-05T02:22:12.756342Z","shell.execute_reply":"2022-11-05T02:22:12.775003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"lf5oq6FQ-dG9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tdQhpx4D-dTX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(df.corr())\nsns.pairplot(df)#plt.show()\n","metadata":{"id":"r1CLzMgs-dcj","outputId":"f9c94406-b763-46f7-ec8a-3eae23d61776","execution":{"iopub.status.busy":"2022-11-05T02:22:12.778974Z","iopub.execute_input":"2022-11-05T02:22:12.779838Z","iopub.status.idle":"2022-11-05T02:22:39.902223Z","shell.execute_reply.started":"2022-11-05T02:22:12.779799Z","shell.execute_reply":"2022-11-05T02:22:39.901010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlations of each feature in dataset, 1 is the best value for correlated data\ncorrmat = df.corr()\ntop_features = corrmat.index\nplt.figure(figsize = (20,20))\n\ng = sns.heatmap(df[top_features].corr(), annot = True, cmap = \"Blues\")\nplt.show()","metadata":{"id":"v2_UsLxS-dhq","outputId":"5142b98c-ce37-4aec-d564-588918a2fc43","execution":{"iopub.status.busy":"2022-11-05T02:22:39.903852Z","iopub.execute_input":"2022-11-05T02:22:39.904731Z","iopub.status.idle":"2022-11-05T02:22:40.809939Z","shell.execute_reply.started":"2022-11-05T02:22:39.904694Z","shell.execute_reply":"2022-11-05T02:22:40.808415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure()\ndf.hist(figsize=(20,20))\nplt.show()","metadata":{"id":"0hLNkOpR-dmT","outputId":"5144da63-40e5-450d-fb3b-cd5b22f96998","execution":{"iopub.status.busy":"2022-11-05T02:22:40.815761Z","iopub.execute_input":"2022-11-05T02:22:40.816204Z","iopub.status.idle":"2022-11-05T02:22:42.940380Z","shell.execute_reply.started":"2022-11-05T02:22:40.816170Z","shell.execute_reply":"2022-11-05T02:22:42.939012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train, Test, Split**","metadata":{"id":"c9GxNf0KA3WG"}},{"cell_type":"code","source":"#Setting independant and target variables, cleaning by dropping categorical and Target (Y) variable (feature)\nX = df.drop(['passResult'],axis=1) #dropped target column\ny = df['passResult']  #target variable\n\n#Splitting Data into training and testing data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42,shuffle=True)\n\nprint(\"X data head\")\nprint(X.head())\nprint (\"Y data head\")\nprint(y.head())\n","metadata":{"id":"q39ZAS_w-drf","outputId":"6a509b25-eae7-4209-96c8-c64ddafbf658","execution":{"iopub.status.busy":"2022-11-05T02:22:42.942880Z","iopub.execute_input":"2022-11-05T02:22:42.943522Z","iopub.status.idle":"2022-11-05T02:22:42.965013Z","shell.execute_reply.started":"2022-11-05T02:22:42.943476Z","shell.execute_reply":"2022-11-05T02:22:42.962731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"MAvDnUb7-d8y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nxgbc = XGBClassifier(max_depth=3, #how many levels of tree to grow, higher the num greater chance of overfitting\n                     subsample = 0.5, #fraction of observations to be randomly sampled for each tree\n                     n_estimators=200,\n                     objective = \"binary:logistic\",\n                     eval_metric=['merror','mlogloss'],\n                     learning_rate=0.1, #alias of eta hyperparam, the step size shrinkage used in update to prevent overfit should be .01-.2\n                     min_child_weight=1, #min sum of weights of all obs rquired in a child, high val can lead to underfitting, tune using CV\n                     reg_alpha=0, #L! loss func regularization term on weights. higher more conservative the model\n                     reg_lambda=1 #L2 loss func regularization term on weights, higher more conservative the model\n                     )\n#more info on hyperparams https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning/notebook\nprint(xgbc)\n\n\nxgbc.fit(X_train, y_train)\ny_predict = xgbc.predict(X_test)\ny_train_predict = xgbc.predict(X_train)\n","metadata":{"id":"pW4hq6cy-eAz","outputId":"edd6ccd6-f4cc-430d-d451-78cdf4cffe4d","execution":{"iopub.status.busy":"2022-11-05T02:22:42.967575Z","iopub.execute_input":"2022-11-05T02:22:42.968101Z","iopub.status.idle":"2022-11-05T02:22:46.317983Z","shell.execute_reply.started":"2022-11-05T02:22:42.968033Z","shell.execute_reply":"2022-11-05T02:22:46.316646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n##################Evalutation of results########################\n# - cross validataion\nscores = cross_val_score(xgbc, X_train, y_train, cv=5)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())\n\n\n'''\nK-Fold Cross Validation\nAs there is never enough data to train your model, removing a part of it for validation poses a problem of underfitting. By reducing the training data, we risk losing important patterns/ trends in data set, which in turn increases error induced by bias. So, what we require is a method that provides ample data for training the model and also leaves ample data for validation. K Fold cross validation does exactly that.\n\nIn K Fold cross validation, the data is divided into k subsets. Now the holdout method is repeated k times, such that each time, one of the k subsets is used as the test set/ validation set and the other k-1 subsets are put together to form a training set. The error estimation is averaged over all k trials to get total effectiveness of our model. As can be seen, every data point gets to be in a validation set exactly once, and gets to be in a training set k-1 times. This significantly reduces bias as we are using most of the data for fitting, and also significantly reduces variance as most of the data is also being used in validation set. Interchanging the training and test sets also adds to the effectiveness of this method. As a general rule and empirical evidence, K = 5 or 10 is generally preferred, but nothing’s fixed and it can take any value.\n\nsklearn provides the functionality for this cross check\n'''\nkfold = KFold(n_splits=10, shuffle=True)\nkf_cv_scores = cross_val_score(xgbc, X_train, y_train, cv=kfold )\nprint(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n","metadata":{"id":"9WSDijPo-eEL","outputId":"85ccfdd2-3029-4ebe-8ad8-120b8774c344","execution":{"iopub.status.busy":"2022-11-05T02:22:46.319819Z","iopub.execute_input":"2022-11-05T02:22:46.324325Z","iopub.status.idle":"2022-11-05T02:23:18.746161Z","shell.execute_reply.started":"2022-11-05T02:22:46.324267Z","shell.execute_reply":"2022-11-05T02:23:18.745096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred = xgbc.predict(X_test)\ncm = confusion_matrix(y_test,ypred)\nprint(cm)\n\n'''\nAccuracy Score is not the best way to measure the fit of the model\n'''\nprint('train accuracy', accuracy_score(y_train, y_train_predict))\nprint('test accuracy', accuracy_score(y_test, ypred))\n","metadata":{"id":"gjsw8Wcp-eLB","outputId":"9b5f90f4-aeee-4956-88e4-2094d8028567","execution":{"iopub.status.busy":"2022-11-05T02:23:18.750999Z","iopub.execute_input":"2022-11-05T02:23:18.751868Z","iopub.status.idle":"2022-11-05T02:23:18.780634Z","shell.execute_reply.started":"2022-11-05T02:23:18.751826Z","shell.execute_reply":"2022-11-05T02:23:18.778948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nxgbc.fit(X_train, y_train,\n        eval_set=[(X_train, y_train), (X_test, y_test)], \n         verbose=False)\n# Load evals result by calling the evals_result() function\n\nevals_result = xgbc.evals_result()\n","metadata":{"id":"N3T94Co1-eN8","execution":{"iopub.status.busy":"2022-11-05T02:23:18.785844Z","iopub.execute_input":"2022-11-05T02:23:18.786722Z","iopub.status.idle":"2022-11-05T02:23:21.949657Z","shell.execute_reply.started":"2022-11-05T02:23:18.786681Z","shell.execute_reply":"2022-11-05T02:23:21.948589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Access complete dict:')\nprint(evals_result)\n\nresults = evals_result\nepochs = len(results[\"validation_0\"][\"merror\"])\nx_axis = range(0, epochs)\n# plot log loss\nfig, ax = pyplot.subplots(figsize=(12, 12))\nax.plot(x_axis, results[\"validation_0\"][\"mlogloss\"], label=\"Train\")\nax.plot(x_axis, results[\"validation_1\"][\"mlogloss\"], label=\"Test\")\nax.legend()\npyplot.ylabel(\"Log Loss\")\npyplot.title(\"XGBoost Log Loss\")\npyplot.show()\n\nfig, ax = pyplot.subplots(figsize=(12, 12))\nax.plot(x_axis, results[\"validation_0\"][\"merror\"], label=\"Train\")\nax.plot(x_axis, results[\"validation_1\"][\"merror\"], label=\"Test\")\nax.legend()\npyplot.ylabel(\"Classification Error\")\npyplot.title(\"XGBoost Classification Error\")\npyplot.show()\n\n","metadata":{"id":"X4IInA9sBg7N","outputId":"4d216890-d5e7-4f47-e934-4f34fdb6d9d5","execution":{"iopub.status.busy":"2022-11-05T02:23:21.951029Z","iopub.execute_input":"2022-11-05T02:23:21.951761Z","iopub.status.idle":"2022-11-05T02:23:22.564571Z","shell.execute_reply.started":"2022-11-05T02:23:21.951723Z","shell.execute_reply":"2022-11-05T02:23:22.562808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(xgbc.feature_importances_)\n\nfeat_importances = pd.Series(xgbc.feature_importances_, index = X.columns)\nfeat_importances.nlargest(5).plot(kind = 'barh')\n\n\n\n\n#wrapping up\nplt.show()","metadata":{"id":"VXXIFPW6BhGF","outputId":"1ee6d109-c054-40db-db74-87591f8469b8","execution":{"iopub.status.busy":"2022-11-05T02:23:22.566113Z","iopub.execute_input":"2022-11-05T02:23:22.566459Z","iopub.status.idle":"2022-11-05T02:23:22.793841Z","shell.execute_reply.started":"2022-11-05T02:23:22.566429Z","shell.execute_reply":"2022-11-05T02:23:22.792666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pickling and dumping, saving model in pkl format\nfile = open('xgbcl_model.pkl', 'wb')\npickle.dump(xgbc, file)\n","metadata":{"id":"jmu9SxmCBhSf","execution":{"iopub.status.busy":"2022-11-05T02:23:22.795272Z","iopub.execute_input":"2022-11-05T02:23:22.795675Z","iopub.status.idle":"2022-11-05T02:23:22.824093Z","shell.execute_reply.started":"2022-11-05T02:23:22.795643Z","shell.execute_reply":"2022-11-05T02:23:22.823156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"oJ8gEVCWCYpY"}}]}